Concentration = if_else(subs_value == 0,
"Less than LoD",
Concentration, missing =  Concentration)
)
# Impute censored data ----------------------------------------------------
unique(data$Concentration)
data$censored <- data$Concentration %in% c("Less than LoQ", "Less than LoD")
(frac_censored <- select(data, CAS_No, censored) %>%
group_by(CAS_No) %>%
summarise(percent = mean(censored, na.rm = TRUE),
n = n()) %>%
arrange(desc(percent)))
select(data, CAS_No, station_co, censored) %>%
group_by(CAS_No, station_co) %>%
summarise(percent = mean(censored, na.rm = TRUE),
n = n()) %>%
arrange(desc(percent))
# select substances with lower then 80 percent of the values below dl
valid_subs <- filter(frac_censored, percent < 0.8)
valid_subs <- valid_subs$CAS_No
data <- filter(data, CAS_No %in% valid_subs)
select(data, CAS_No, emission_water_raw)
select(data, CAS_No, emission_water_raw) %>% filter(is.na(emission_water_raw))
select(data, CAS_No, emission_water_raw) %>% filter(is.na(emission_water_raw)) %>% unique()
unique(data$CAS_No)
# # total #
#
# data$waarde <- data$subs_value
# data$waarde[data$waarde == 0] <- NA
#
# data_cen <- arrange(data, waarde) %>%
#   mutate(id = 1:nrow(data))
#
#
# ros_mod <- ros(data$waarde, data$censored, forwardT = "log", reverseT = "exp")
# ros_df <- as.data.frame(ros_mod)
#
# ros_df <- mutate(ros_df, id = 1:nrow(ros_df)) %>%
#   select(-pp)
#
# ros_imp <- ros_df$modeled
#
# # joining the imputed values to the data #
# data_cen <- left_join(data_cen, ros_df, by = c("id", "subs_value" = "obs", "censored")) %>%
#   rename(subs_value_dl = modeled)
#
# # replace NA values with original #
# data_cen <- mutate(data_cen, subs_value_dl = case_when(is.na(subs_value_dl) ~ subs_value,
#                                                        TRUE ~ subs_value_dl)) %>%
#   select(-waarde, -id)
#
# # data_sub$subs_value_dl <- ros_imp
#
# # check if values align #
# filter(data_cen, censored == FALSE) %>%
#   mutate(correct =subs_value == subs_value_dl) %>%
#   summarise(correct_pct = mean(correct))
## ##
#
#
# impute with ROS per substance #
data_cen <- NULL
substances <- unique(data$CAS_No)
# sub <- "120-18-3"
for (sub in substances) {
data_sub <- filter(data, CAS_No == sub) %>%
arrange(subs_value)
data_sub$waarde <- data_sub$subs_value
data_sub$waarde[data_sub$waarde == 0] <- NA
data_sub <- arrange(data_sub, waarde) %>%
mutate(id = 1:nrow(data_sub))
if(mean(data_sub$censored) == 1){
data_sub$subs_value_dl <- as.numeric(NA)
# next
}
else{
# impute #
ros_mod <- ros(data_sub$waarde, data_sub$censored, forwardT = "log", reverseT = "exp")
ros_df <- as.data.frame(ros_mod)
ros_df <- mutate(ros_df, id = 1:nrow(ros_df)) %>%
select(-pp)
ros_imp <- ros_df$modeled
# joining the imputed values to the data #
data_sub <- left_join(data_sub, ros_df, by = c("id", "subs_value" = "obs", "censored")) %>%
rename(subs_value_dl = modeled)
}
# replace NA values with original #
data_sub <- mutate(data_sub, subs_value_dl = case_when(is.na(subs_value_dl) ~ subs_value,
TRUE ~ subs_value_dl)) %>%
select(-waarde, -id)
# data_sub$subs_value_dl <- ros_imp
# check if values align #
filter(data_sub, censored == FALSE) %>%
mutate(correct = subs_value == subs_value_dl) %>%
summarise(correct_pct = mean(correct))
# binding it together #
data_cen <- bind_rows(data_cen, data_sub)
}
# creating intermediate datset #
data_intermediate <- data
# saving the total data with censored obs.#
data <- data_cen
# create data for later use #
data <- select(
data,
-HAROID,
-REGION,
-MAINDOWN,
-LAKEDATAID,
-LAKE_DEPTH,  # always the same
-ICATCH,  # always the same
-loc_sp,
-loc_in,
-frac_GDPEP,
-f_agr,
-emission_air_raw,
-emission_water_raw,
-emission_ww_raw,
-emission_soil_raw,
-mult_groups,
-reach,
-pest,
-pharma,
-drydep_n2,  # drydep_n1 & drydep_n2 are the same?
-WQPARREG,  # always the same
-DHSLC_3,  # only 0 values for the variables below
-SLC_3,
-SLC_23,
-SLC_26,
-SLC_32,
-SLC_33,
-SLC_35,
-SLC_36,
-SLC_41,
-SLC_51,
-SLC_53,
-SLC_54,
-SLC_56,
-SLC_57,
-SLC_58,
-SLC_59,
-SLC_60,
-SLC_66,
-SLC_70,
-SLC_74,
-SLC_75
)
#miss_var_summary(data)
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
source('P:/1209104-solutions/JDS_ML/github_repo_JDS_ML/JDS_ML/emerging_sub_worldbank_R/scripts/Cleaning_data.R', encoding = 'UTF-8', echo=TRUE)
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
# create test and training data #
set.seed(1234)
N <- nrow(df)
target <- round(0.75 * N)
gp <- runif(N)
# splitting the data
df_train <- df[gp < 0.75, ]
df_test <- df[gp >= 0.75, ]
# Cross validation Plan #
nRows <- nrow(df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
fmla <- as.formula("subs_value_dl ~ .")
# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
source('P:/1209104-solutions/JDS_ML/github_repo_JDS_ML/JDS_ML/emerging_sub_worldbank_R/scripts/Cleaning_data.R', encoding = 'UTF-8', echo=TRUE)
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
unique(df$CAS_No)
# create test and training data #
set.seed(1234)
N <- nrow(df)
target <- round(0.75 * N)
gp <- runif(N)
# splitting the data
df_train <- df[gp < 0.75, ]
df_test <- df[gp >= 0.75, ]
# Cross validation Plan #
nRows <- nrow(df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
fmla <- as.formula("subs_value_dl ~ .")
# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
source('P:/1209104-solutions/JDS_ML/github_repo_JDS_ML/JDS_ML/emerging_sub_worldbank_R/scripts/Cleaning_data.R', encoding = 'UTF-8', echo=TRUE)
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
# create test and training data #
set.seed(1234)
N <- nrow(df)
target <- round(0.75 * N)
gp <- runif(N)
# splitting the data
df_train <- df[gp < 0.75, ]
df_test <- df[gp >= 0.75, ]
# Cross validation Plan #
nRows <- nrow(df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
fmla <- as.formula("subs_value_dl ~ .")
# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
# create test and training data #
set.seed(1234)
N <- nrow(df)
target <- round(0.75 * N)
gp <- runif(N)
# splitting the data
df_train <- df[gp < 0.75, ]
df_test <- df[gp >= 0.75, ]
# Cross validation Plan #
nRows <- nrow(df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
fmla <- as.formula("subs_value_dl ~ .")
# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
