# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
source('P:/1209104-solutions/JDS_ML/github_repo_JDS_ML/JDS_ML/emerging_sub_worldbank_R/scripts/Cleaning_data.R', encoding = 'UTF-8', echo=TRUE)
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
# create test and training data #
set.seed(1234)
N <- nrow(df)
target <- round(0.75 * N)
gp <- runif(N)
# splitting the data
df_train <- df[gp < 0.75, ]
df_test <- df[gp >= 0.75, ]
# Cross validation Plan #
nRows <- nrow(df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
fmla <- as.formula("subs_value_dl ~ .")
# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
# create test and training data #
set.seed(1234)
N <- nrow(df)
target <- round(0.75 * N)
gp <- runif(N)
# splitting the data
df_train <- df[gp < 0.75, ]
df_test <- df[gp >= 0.75, ]
# Cross validation Plan #
nRows <- nrow(df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
fmla <- as.formula("subs_value_dl ~ .")
# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
# Loading libraries -------------------------------------------------------
library(tidyverse)
library(naniar)
library(vtreat)
library(ranger)
library(xgboost)
library(caret)
library(tictoc)
library(h2o)
# Loading data ------------------------------------------------------------
df <- read_rds("data/modified/compact_data.rds") %>%
select(-subs_value) # temporary
# Cleaning data for feature table #
df <- select(df, -SUBID:-Concentration, -valid_measurement, -sub_groups, -censored)  # -subs_value, -censored
# first test removing all missing values (for now) #
df <- na.omit(df)
# create test and training data #
set.seed(1234)
N <- nrow(df)
target <- round(0.75 * N)
gp <- runif(N)
# splitting the data
df_train <- df[gp < 0.75, ]
df_test <- df[gp >= 0.75, ]
# Cross validation Plan #
nRows <- nrow(df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
fmla <- as.formula("subs_value_dl ~ .")
# test model  random forrest #
(subs_model_rf <-
ranger(
formula = fmla,
data = df_train,
num.trees = 500,
respect.unordered.factors = "order"
))
df_test$rf_pred <- predict(subs_model_rf, df_test)$predictions
# RMSE on test data
mutate(df_test, residual = subs_value_dl - rf_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
# plot model performance
ggplot(df_test, aes(x = rf_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_rf", y ="concentration (μg/l)")
rf_pred <- df_test$rf_pred
df_test <- select(df_test, -rf_pred)
# test model xgboost #
df_train_xg <- select(df_train, -subs_value_dl)
df_test_xg <- select(df_test, -subs_value_dl)
cv <-
xgb.cv(
data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 100,
nfold = 5,
objective = "reg:linear",
eta = 0.3,
max_depth = 6,
early_stopping_rounds = 10,
verbose = 0
)
elog <- cv$evaluation_log
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min (train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
subs_model_xgb <- xgboost(data = as.matrix(df_train_xg),
label = df_train$subs_value_dl,
nrounds = 15,
objective = "reg:linear",
eta = 0.3,
depth = 6,
verbose = 0)
df_test$xgb_pred <- predict(subs_model_xgb, as.matrix(df_test_xg))
mutate(df_test, residual = subs_value_dl - xgb_pred) %>%
summarise(rmse = sqrt(mean(residual ^2)))
ggplot(df_test, aes(x = xgb_pred, y = subs_value_dl)) +
geom_point() +
geom_abline() +
labs(x ="prediction_xgb", y ="concentration (μg/l)")
df_test$rf_pred <- rf_pred
# check both models #
mutate(df_test, residual_rf = subs_value_dl - rf_pred,
residual_xgb = subs_value_dl - xgb_pred) %>%
summarise(rmse_rf = sqrt(mean(residual_rf ^2)),
rmse_xgb = sqrt(mean(residual_xgb ^2)))
library(tidyverse)
library(readxl)
# load data ---------------------------------------------------------------
subs <- read_excel("data/raw/MLos_all substances_calculations_v3_fromWP17.xlsx", sheet = 1)
subs
# load data ---------------------------------------------------------------
subs <- read_excel("data/raw/MLos_all substances_calculations_v3_fromWP17.xlsx", sheet = 1, skip = 3)
mod_subs <- read_csv2("data/unique_CAS")
mod_subs <- read_csv("data/unique_CAS")
mod_subs <- read_csv("data/unique_CAS.csv")
subs
setdiff(mod_subs$CAS, subs$`CAS Number`)
setdiff(str_remove(mod_subs$CAS, "_cas"), subs$`CAS Number`)
setdiff(subs$`CAS Number`, str_remove(mod_subs$CAS, "_cas"))
# Kevin Ouwerkerk
# 2019-11-18
# Loading libraries -------------------------------------------------------
library(readxl)
library(RSQLite)
library(naniar)
library(arrow)
library(tidyverse)
library(NADA)
# Loading data ------------------------------------------------------------
geo_hydro <- read_tsv("data/raw/GeoData.txt") %>%
filter(HAROID == 9600704)
catch <- read_excel("data/raw/NewHypeSchematisation.xlsx", sheet = "CumCat") %>%
select(SUBID, CumCat_km2)
measurements <-
read_excel(path = "data/raw/JDS_Query met pivot.xlsx", sheet = "DBQuery") %>%
filter(Sample_Matrix == "Water - Surface water", CAS_No != "N/A") %>%
select(
Station_Code,
Substance,
CAS_No,
H_Unit,
Concentration,
`Data value`,
`Valid measurement`
) %>%
rename(subs_value = `Data value`,
valid_measurement = `Valid measurement`)
measurements$H_Unit[measurements$H_Unit == "mg/L"] <- "mg/l"
measurements_mapping <- read_csv2(file = "data/raw/MappingJDS_Define.csv") %>%
filter(HAROID == 9600704) %>%
select(station_co, SUBID, distance_t, CumAreakkm2)
demo <- read_excel(path = "data/raw/copy_locators_hypefinal_Nov2017.xlsx", sheet = "locators") %>%
select(SC, CountryCorrFinal, GDPEP)
countries <- read_excel(path = "data/raw/copy_locators_hypefinal_Nov2017.xlsx", sheet = "Countries") %>%
rename(country = `Countries in Ehype`, country_nr = Nr) %>%
select(country, country_nr)
country_gdpep <- read_tsv("data/raw/GeoData.txt") %>%
select(SUBID) %>%
left_join(demo, by = c("SUBID" = "SC")) %>%
left_join(countries, by = c("CountryCorrFinal" = "country")) %>%
group_by(CountryCorrFinal, country_nr) %>%
summarise(coun_gdpep = sum(GDPEP, na.rm = TRUE)) %>%
ungroup()
agrlu <- read_excel(path = "data/raw/copy_locators_hypefinal_Nov2017.xlsx", sheet = "LU") %>%
select(SUBID, Agr) %>%
rename(area_agr = Agr)
demo <- left_join(demo, countries, by = c("CountryCorrFinal" = "country")) %>%
left_join(agrlu, by = c("SC" = "SUBID")) %>%
left_join(country_gdpep, by = c("CountryCorrFinal", "country_nr")) %>%
mutate(frac_GDPEP = GDPEP / coun_gdpep)
conn <- dbConnect(RSQLite::SQLite(), "data/raw/substance_properties.db")
dbListTables(conn)
sub_props <-
dbGetQuery(
conn,
"SELECT ID, CAS, property, value FROM substance_properties WHERE property IN ('Molar mass [Da]', 'log Kow', 'Kbiodeg [1/s]', 'Ks')"
) %>%
mutate(value = as.numeric(value)) %>%
filter(CAS %in% measurements$CAS_No) %>%
spread(key = property, value = value) %>%
select(CAS, `Kbiodeg [1/s]`, `log Kow`, `Molar mass [Da]`, Ks) %>%
group_by(CAS) %>%
summarise(
molar_mass = mean(`Molar mass [Da]`, na.rm = TRUE),
log_kow = mean(`log Kow`, na.rm = TRUE),
kbiodeg = mean(`Kbiodeg [1/s]`, na.rm = TRUE),
ks = mean(Ks, na.rm = TRUE)
) %>%
ungroup()
sub_groups <- dbGetQuery(
conn,
"SELECT CAS, CODE FROM substances"
) %>%
filter(CAS %in% measurements$CAS_No) %>%
mutate(CODE = tolower(CODE)) %>%
mutate(pest = str_detect(CODE, "pest"),
pharma = str_detect(CODE, "pharma"),
reach = str_detect(CODE, "reach")
) #%>%
# select(-CODE)
sub_groups <- sub_groups[!duplicated(sub_groups$CAS), ]
data_tot <-
left_join(measurements_mapping,
measurements ,
by = c("station_co" = "Station_Code")) %>%
left_join(geo_hydro, by = "SUBID") %>%
left_join(catch, by = "SUBID") %>%
left_join(demo, by = c("SUBID" = "SC")) %>%
left_join(sub_props, by = c("CAS_No" = "CAS")) %>%
left_join(sub_groups, by = c("CAS_No" = "CAS"))
data <- data_tot %>%
select(
HAROID,
MAINDOWN,
SUBID,
CountryCorrFinal,
country_nr,
LAKEREGION,
REGION,
WQPARREG,
POURX,
POURY,
TARGETX,
TARGETY,
CENTERX,
CENTERY,
LATITUDE,
LONGITUDE,
station_co,
Substance,
CAS_No,
H_Unit,
Concentration,
subs_value,
valid_measurement,
kbiodeg,
log_kow,
molar_mass,
ks,
reach,
pest,
pharma,
AREA,
area_agr,
UPAREA,
RIVLEN,
ELEV_MEAN,
ELEV_STD,
SLOPE_MEAN,
RELIEF,
SLC_1:CumCat_km2,
GDPEP,
frac_GDPEP,
distance_t,
CumAreakkm2
) %>%
mutate(  # recalculating units to one standard #
subs_value = case_when(
H_Unit == "mg/l" ~ subs_value * 1000,
H_Unit == "mg/kg" ~ subs_value * 1000,
TRUE ~ subs_value
),
H_Unit = case_when(H_Unit == "mg/l" ~ "µg/l",
H_Unit == "mg/kg" ~ "µg/kg",
TRUE ~ H_Unit)
) %>%
filter(H_Unit != "µg/kg")
# removing missing measurement
data <- data[!is.na(data$subs_value), ]
subs_props
sub_props
setdiff(data$CAS_No, sub_props$CAS)
setdiff(data$CAS_No, subs$`CAS Number`)
setdiff(sub_props$CAS, subs$`CAS Number`)
setdiff(subs$`CAS Number`, sub_props$CAS)
dbGetQuery(
conn,
"SELECT ID, CAS, property, value FROM substance_properties WHERE property IN ('Molar mass [Da]', 'log Kow', 'Kbiodeg [1/s]', 'Ks')"
) %>%
mutate(value = as.numeric(value)) %>%
filter(CAS %in% measurements$CAS_No) %>%
spread(key = property, value = value)
dbGetQuery(
conn,
"SELECT ID, CAS, property, value FROM substance_properties %>%
mutate(value = as.numeric(value)) %>%
filter(CAS %in% measurements$CAS_No) %>%
spread(key = property, value = value)
dbGetQuery(
conn,
"SELECT ID, CAS, property, value FROM substance_properties") %>%
mutate(value = as.numeric(value)) %>%
filter(CAS %in% measurements$CAS_No) %>%
spread(key = property, value = value)
dbGetQuery(
conn,
"SELECT ID, CAS, property, value FROM substance_properties")
dbGetQuery(
conn,
"SELECT ID, CAS, property, value FROM substance_properties") %>% distinct(property)
